{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erfanmiahi/Library/Caches/pypoetry/virtualenvs/rlr-T4Exv07c-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Tuple, Union, Callable\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    GenerationConfig\n",
    ")\n",
    "from tensordict.tensordict import TensorDict\n",
    "\n",
    "# Configure logging using logging library\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class ReasoningEnv(ABC):\n",
    "    \"\"\"It has the responsibility to simulate the environment that the agent is interacting with.\n",
    "    Environment processes one query at a time.\n",
    "    Core functionalities:\n",
    "    - step():\n",
    "    - rollout():\n",
    "    - reset():\n",
    "    - close():\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 cfg: dict, \n",
    "                 tokenizer: AutoTokenizer,\n",
    "                 dataset_path: Union[str, Path] = None,\n",
    "                 dataset: Dataset = None,\n",
    "                 data_generator: Callable = None):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            cfg (dict): _description_\n",
    "            tokenizer (AutoTokenizer): tokenizer includes both the tokenizer and vocab size\n",
    "            dataset_path (Union[str, Path]): path to the dataset\n",
    "            dataset (Dataset): dataset\n",
    "        \"\"\"\n",
    "        self._cfg = cfg\n",
    "        self._tokenizer = tokenizer\n",
    "        self._dataset = self._initialize_dataset(dataset=dataset, dataset_path=dataset_path, data_generator=data_generator)\n",
    "        self._current_state = None\n",
    "        self._current_query_idx = 0\n",
    "\n",
    "    def _initialize_dataset(self, dataset=None, dataset_path=None, data_generator=None):\n",
    "        if (dataset and dataset_path) or (dataset and data_generator) or (dataset_path and data_generator):\n",
    "            raise ValueError(\"Provide only one of dataset, dataset_path, or data_generator\")\n",
    "        \n",
    "        if dataset_path is not None:\n",
    "            return load_dataset(dataset_path)\n",
    "        elif dataset is not None:\n",
    "            return dataset\n",
    "        elif data_generator is not None:\n",
    "            raise NotImplementedError(\"data_generator is not implemented\")\n",
    "        else:\n",
    "            raise ValueError(\"Provide either dataset_path or dataset\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def step(self, action: Union[str, torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor, bool, bool, dict]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            action (Union[str, torch.Tensor]): _description_\n",
    "\n",
    "        Returns:\n",
    "            Observation: _description_\n",
    "            Reward: _description_\n",
    "            Terminated: _description_\n",
    "            Truncated: _description_\n",
    "            Info: _description_\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def rollout(self, max_steps: int, \n",
    "                policy: AutoModelForCausalLM = None, \n",
    "                generation_config: GenerationConfig = None\n",
    "                ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        pass\n",
    "        \n",
    "    def reset(self) -> Tuple[torch.Tensor, Union[TensorDict, dict]]:\n",
    "        self._current_state = self._dataset[self._current_query_idx]['input_ids']\n",
    "        self._current_query_idx += 1\n",
    "\n",
    "        info_ = {}\n",
    "        return self._current_state, info_\n",
    "    \n",
    "    @abstractmethod\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "class TokenLevelReasoningEnv(ReasoningEnv):\n",
    "    \n",
    "    def step(self, action: Union[str, torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor, bool, bool, dict]:\n",
    "        pass\n",
    "\n",
    "    def rollout(self, max_steps: int, \n",
    "                policy: AutoModelForCausalLM = None, \n",
    "                generation_config: GenerationConfig = None\n",
    "                ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        \n",
    "        \n",
    "        if policy is None:\n",
    "            # use a uniform policy to randomly sample actions from the tokenizer\n",
    "            class UniformPolicy(AutoModelForCausalLM):\n",
    "                def __init__(self, tokenizer: AutoTokenizer):\n",
    "                    self._tokenizer = tokenizer\n",
    "\n",
    "                def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "                    return torch.randint(0, self._tokenizer.vocab_size)\n",
    "                \n",
    "                def generate(self, input_ids: torch.Tensor, generation_config: GenerationConfig) -> torch.Tensor:\n",
    "                    return torch.randint(0, self._tokenizer.vocab_size, size=input_ids.shape)\n",
    "                \n",
    "            policy = UniformPolicy(self._tokenizer)\n",
    "\n",
    "        if generation_config is None:\n",
    "            generation_config = GenerationConfig(\n",
    "                max_new_tokens=max_steps,\n",
    "                temperature=1.0,\n",
    "                top_k=0.0,\n",
    "                top_p=1.0,\n",
    "                do_sample=True,\n",
    "            )\n",
    "\n",
    "        response = policy.generate(input_ids=self._current_state, generation_config=generation_config)\n",
    "\n",
    "        self._current_state = response.input_ids\n",
    "\n",
    "        return self._current_state, self._current_state\n",
    "\n",
    "# implement this vectorized version of the environment using vmap in python. Make sure the implementation is optimal.\n",
    "# You need to make sure that the dataset is loaded beforehand and each distinct part goes to a seperate environment.\n",
    "class VecReasoningEnv:\n",
    "\n",
    "    def __init__(self, cfg: dict, tokenizer: AutoTokenizer, dataset: Dataset):\n",
    "        self._cfg = cfg\n",
    "        self._tokenizer = tokenizer\n",
    "        self._dataset = dataset\n",
    "        self._envs = [TokenLevelReasoningEnv(cfg, tokenizer, dataset) for _ in range(len(dataset))]\n",
    "\n",
    "    def step(self, action: Union[str, torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor, bool, bool, dict]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMPLE_CHAT_TEMPLATE = \"{% for message in messages %}{{message['role'].capitalize() + ': ' + message['content'] + '\\n\\n'}}{% endfor %}{% if add_generation_prompt %}{{ 'Assistant: ' }}{% endif %}\"\n",
    "USER_PREFIX_PROMPT = \"Your role as an assistant involves thoroughly exploring questions through a systematic long thinking process before providing the final precise and accurate solutions. This requires engaging in a comprehensive cycle of analysis, summarizing, exploration, reassessment, reflection, backtracing, and iteration to develop well-considered thinking process. Please structure your response into two main sections: Thought and Solution. In the Thought section, detail your reasoning process using the specified format: <|begin_of_thought|> {thought with steps separated with ' '} <|end_of_thought|> Each step should include detailed considerations such as analisying questions, summarizing relevant findings, brainstorming new ideas, verifying the accuracy of the current steps, refining any errors, and revisiting previous steps. In the Solution section, based on various attempts, explorations, and reflections from the Thought section, systematically present the final solution that you deem correct. The solution should remain a logical, accurate, concise expression style and detail necessary step needed to reach the conclusion, formatted as follows: <|begin_of_solution|> {final formatted, precise, and clear solution} <|end_of_solution|> Now, try to solve the following question through the above guidelines:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Padding token is None, setting it to eos_token: <｜end▁of▁sentence｜>\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:28<00:00, 14.19s/it]\n",
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk.\n",
      "INFO:__main__:Loaded dataset: Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 7473\n",
      "})\n",
      "INFO:__main__:Dataset Characteristics: {'question': Value(dtype='string', id=None), 'answer': Value(dtype='string', id=None)}\n",
      "INFO:__main__:Dataset Length: 7473\n",
      "INFO:__main__:Dataset Example: (7473, 2)\n"
     ]
    }
   ],
   "source": [
    "# Model paths\n",
    "base_model_path = \"deepseek-ai/deepseek-math-7b-instruct\"\n",
    "\n",
    "# Initialize tokenizer with padding token\n",
    "# TODO: understanding right padding and left padding and how it influences the performance\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_path, padding_side=\"left\", trust_remote_code=True, return_tensors=\"pt\"\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    # TODO: learn what it means EXACTLY TO SET EOS == PAD TOKEN\n",
    "    logger.info(f\"Padding token is None, setting it to eos_token: {tokenizer.eos_token}\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "if tokenizer.chat_template is None:\n",
    "    logger.info(f\"Chat template is None, setting it to SIMPLE_CHAT_TEMPLATE: {SIMPLE_CHAT_TEMPLATE}\")\n",
    "    tokenizer.chat_template = SIMPLE_CHAT_TEMPLATE\n",
    "\n",
    "# Load all required models\n",
    "# value_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     base_model_path,\n",
    "#     trust_remote_code=True,\n",
    "#     num_labels=1,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.float16,\n",
    "# )\n",
    "# logger.debug(f\"Value Model Architecture: {value_model}\")\n",
    "\n",
    "# reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     base_model_path,\n",
    "#     trust_remote_code=True,\n",
    "#     num_labels=1,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.float16,\n",
    "# )\n",
    "# logger.debug(f\"Reward Model Architecture: {reward_model}\")\n",
    "policy = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    offload_folder=\"offload/yo_v1\",\n",
    ")\n",
    "logger.debug(f\"Policy Model Architecture: {policy}\")\n",
    "\n",
    "# ref_policy = AutoModelForCausalLM.from_pretrained(\n",
    "#     base_model_path,\n",
    "#     trust_remote_code=True,\n",
    "#     device_map=\"auto\",\n",
    "#     torch_dtype=torch.float16,\n",
    "# )\n",
    "# logger.debug(f\"Ref Policy Model Architecture: {ref_policy}\")\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\n",
    "    \"openai/gsm8k\",\n",
    "    'main',\n",
    "    split=\"train\",                                          \n",
    ")\n",
    "logger.info(f\"Loaded dataset: {dataset}\")\n",
    "logger.info(f\"Dataset Characteristics: {dataset.features}\")\n",
    "logger.info(f\"Dataset Length: {len(dataset)}\")\n",
    "logger.info(f\"Dataset Example: {dataset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10/10 [00:00<00:00, 1807.34 examples/s]\n",
      "INFO:root:{'answer': '72', 'input_ids': [100000, 5726, 25, 39203, 480, 5151, 34406, 276, 207, 19, 23, 280, 711, 3997, 279, 6511, 11, 285, 937, 838, 5151, 3222, 372, 1313, 34406, 279, 3638, 13, 1724, 1313, 34406, 1216, 39203, 480, 6926, 16369, 279, 6511, 285, 3638, 30, 185, 7900, 2806, 3458, 457, 3458, 11, 285, 1957, 520, 2328, 3510, 2383, 357, 63962, 90, 1424, 185, 185, 77398, 25]}\n"
     ]
    }
   ],
   "source": [
    "# TODO: this CoT is specialized for deepseek-math-7b-instruct/rl \n",
    "# https://huggingface.co/deepseek-ai/deepseek-math-7b-instruct\n",
    "# make a proper function that is model agnostic in later refactoring\n",
    "def apply_cot_prompt(question: str) -> str:\n",
    "    return question + \"\\nPlease reason step by step, and put your final answer within \\\\boxed{}.\"\n",
    "\n",
    "def preprocess_answer(answer: str) -> str:\n",
    "    # Extract the number after '#### '\n",
    "    return answer.split('#### ')[-1]\n",
    "\n",
    "def tokenize(row: dict) -> dict:\n",
    "    # Create messages format for the chat template\n",
    "    row['question'] = apply_cot_prompt(row['question'])\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': row['question']},\n",
    "        # {'role': 'assistant', 'content': preprocess_answer(row['answer'])}\n",
    "    ]\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True, \n",
    "        add_generation_prompt=True, \n",
    "        padding=False # padding is set because of memory optimization\n",
    "        ) \n",
    "    return {'input_ids': input_ids, 'answer': preprocess_answer(row['answer'])}\n",
    "\n",
    "# Update the dataset mapping\n",
    "tokenized_dataset = dataset.select(range(10)).map(tokenize, remove_columns=dataset.column_names)\n",
    "\n",
    "logging.info(tokenized_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 84])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erfanmiahi/Library/Caches/pypoetry/virtualenvs/rlr-T4Exv07c-py3.12/lib/python3.12/site-packages/transformers/generation/utils.py:2137: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on mps. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('mps') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "INFO:root:User: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "Please reason step by step, and put your final answer within \\boxed{}.\n",
      "\n",
      "Assistant: Natalia sold 48 clips in April.\n",
      "In May, she sold half as many clips as she did in April, so she sold 48/2 = 24 clips in May.\n",
      "To find the total number of clips she sold in April and May, we need to add the number of clips sold in April to the number of clips sold in May, which is 48 + 24 = 72 clips.\n",
      "So the answer is $\\boxed{72}$.\n"
     ]
    }
   ],
   "source": [
    "# Implementation of GRPO algorithm\n",
    "iter_num = 1\n",
    "step_num = 1\n",
    "epsilon = 0.1\n",
    "beta = 0.1\n",
    "mu = 0.1\n",
    "batch_size = 3\n",
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=1000,\n",
    "    temperature=1.0,\n",
    "    top_k=0.0,\n",
    "    top_p=1.0,\n",
    "    do_sample=True,\n",
    ")\n",
    "# reward_func = lambda x: x['answer'] == x['answer']\n",
    "for i in range(iter_num):\n",
    "    # ref_model.load_state_dict(policy.state_dict())\n",
    "    # ref_model.eval()\n",
    "    # ref_model.to(policy.device)\n",
    "    for step in range(step_num):\n",
    "        batch_data = tokenized_dataset.select(range(batch_size))\n",
    "        batch_data = tokenizer.pad({'input_ids': batch_data['input_ids']}, padding=True, return_tensors='pt')\n",
    "        print(batch_data['input_ids'].shape)\n",
    "        # old_policy.load_state_dict(policy.state_dict())\n",
    "        policy_output = policy.generate(input_ids=batch_data['input_ids'], generation_config=generation_config)\n",
    "        policy_output = tokenizer.decode(policy_output[0], skip_special_tokens=True)\n",
    "        logging.info(policy_output)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<｜begin▁of▁sentence｜>User: Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\\nPlease reason step by step, and put your final answer within \\\\boxed{}.\\n\\nAssistant: First calculate how much money Betty's parents gave\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(policy_output[2], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
       "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
       "         100001, 100001, 100001, 100001, 100000,   5726,     25,  39203,    480,\n",
       "           5151,  34406,    276,    207,     19,     23,    280,    711,   3997,\n",
       "            279,   6511,     11,    285,    937,    838,   5151,   3222,    372,\n",
       "           1313,  34406,    279,   3638,     13,   1724,   1313,  34406,   1216,\n",
       "          39203,    480,   6926,  16369,    279,   6511,    285,   3638,     30,\n",
       "            185,   7900,   2806,   3458,    457,   3458,     11,    285,   1957,\n",
       "            520,   2328,   3510,   2383,    357,  63962,     90,   1424,    185,\n",
       "            185,  77398,     25,  39203,    480,   5151,    207,     19,     23,\n",
       "          34406,    279,   6511,     13],\n",
       "        [100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
       "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
       "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
       "         100001, 100001, 100000,   5726,     25,    423,   1227,  74964,    363,\n",
       "             16,     17,    274,   5064,    327,  82996,   3891,     13,  51748,\n",
       "             11,    838,    953,   1216,    207,     20,     15,   4063,    280,\n",
       "          82996,   3891,     13,   1724,   1266,   1216,    838,   6665,     30,\n",
       "            185,   7900,   2806,   3458,    457,   3458,     11,    285,   1957,\n",
       "            520,   2328,   3510,   2383,    357,  63962,     90,   1424,    185,\n",
       "            185,  77398,     25,   2130,   5168,    327,    207,     20,     15,\n",
       "           4063,    280,  82996,   3891],\n",
       "        [100000,   5726,     25,  30808,    317,  13307,   3054,    327,    245,\n",
       "            761,  14156,    588,   7025,    363,     16,     15,     15,     13,\n",
       "          30808,    643,    889,   3222,    280,    254,   3054,    838,   3277,\n",
       "             13,   5067,   6866,   6143,    276,   2102,    711,    363,     16,\n",
       "             20,    327,    344,   5487,     11,    285,    711,  52267,   9682,\n",
       "            372,   1266,    372,    711,   6866,     13,   1724,   1266,    691,\n",
       "           3054,   1217,  30808,    933,    276,   3471,    254,  14156,     30,\n",
       "            185,   7900,   2806,   3458,    457,   3458,     11,    285,   1957,\n",
       "            520,   2328,   3510,   2383,    357,  63962,     90,   1424,    185,\n",
       "            185,  77398,     25,   5904,  11462,    946,   1266,   3054,  30808,\n",
       "              6,     82,   6866,   4366]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Dataset({\n",
      "    features: ['input_ids'],\n",
      "    num_rows: 6447\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# def tokenize(row: dict) -> dict:\n",
    "#     row['messages'] = row['messages'][:1]\n",
    "#     input_ids = tokenizer.apply_chat_template(row['messages'][:1], tokenize=True, add_generation_prompt=True, padding=False)\n",
    "#     return {'input_ids': input_ids}\n",
    "\n",
    "# tokenized_dataset = dataset.map(tokenize, remove_columns=dataset.column_names) # call it dataset later for GC reasons\n",
    "\n",
    "# logging.info(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['User: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\\n\\nAssistant: ~~Natalia sold 2,769 clips to her peers in April (101 clips sold in May), and ~~Natalia sold 935 clips to her friends in April (73 clips sold in May), ~~Natalia sold 100 clips to 21 of her friends in May, and ~~Natalia sold 49 of her 33 friends in May. How many clips did Natalia sell to her friends in April and May?\\n\\nAssistant: Natalia sold all of the girls’ prints, numbers, and legend prints for $70.25 in April. What was the value of these in April and May', \"User: Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\\n\\nAssistant: \\nTrainer: \\nRube: Now her appearance regular, hers can attract paying customers. So, Rube got $10 an hour to look over and teach some little trouble faces.\\n\\nHow much did she win? And how much compensation would he send? `If a customer finds training an attractive way to spend time with a human if the trainer is willing, they will much more likely recommend to come over and visit them personally. I think you can do well paying 12 $ per hour training.` \\nPerhaps a luxury also at a higher rate. Excellent. Someone let's party.\\n\\nA:\\n\\n\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def generate_responses(batch: Dict[str, torch.Tensor], generation_config: GenerationConfig) -> Dict[str, List[str]]:\n",
    "    # Generate from policy model\n",
    "    policy_output = policy.generate(\n",
    "        input_ids=batch['input_ids'].to(policy.device),\n",
    "        generation_config=generation_config,\n",
    "        output_scores=True,\n",
    "        return_dict_in_generate=True  # Return a dictionary to access score\n",
    "    )\n",
    "    # decode the output\n",
    "    policy_output = tokenizer.decode(policy_output.sequences[0], skip_special_tokens=True)\n",
    "    return policy_output\n",
    "\n",
    "responses = []\n",
    "for item in tokenized_dataset.select(range(2)):\n",
    "    item['input_ids'] = torch.tensor(item['input_ids']).reshape(1, -1)\n",
    "    responses.append(generate_responses(item, generation_config))\n",
    "\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50304])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0].scores[0].shape\n",
    "responses[0].scores[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RL Objective = Ref Policy and Policy Logits for the last\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlr-T4Exv07c-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
